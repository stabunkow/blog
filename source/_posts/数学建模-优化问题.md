---
title: 数学建模-优化问题
date: 2021-05-14 12:24:41
mathjax: true
tag: [数学建模, 优化问题, 启发式算法]
---

# 启发式算法

优化问题特别复杂的话，启发式算法就是我们求解问题的一大法宝。

一个基于 **直观或经验构造** 的算法，在 **可接受的花费** 下给出待解决 **优化问题** 的一个 **可行解**。

- 可接受的花费：计算时间和空间能接受
- 优化问题：一定约束条件下,求解一个目标函数的最大值（或最小值）问题。
- 可行解：得到的结果能用于工程实践（不一定非要是最优解）

常见的启发式算法：粒子群算法、模拟退火算法、遗传算法、蚁群算法、禁忌搜索算法。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507165801029.png)

盲目搜索：枚举法、蒙特卡洛模拟。

如果现在要求最值的函数是一个多变量的函数，例如是一个10个变量的函数，要考虑的情况随着变量数呈指数增长。

如果利用了 **中间信息** 来改进搜索策略则称为启发式搜索，任何有助于找到问题的最优解，但不能保证。

启发式算法常见解决问题：TSP(旅行商问题)这类组合优化问题、非线性整数规划问题等，也可以解决。

# 粒子群算法

又称 PSO 算法，通过模拟鸟群觅食行为而发展起来的一种基于 **群体协作** 的搜索算法。

例子主要侧重学习其思想，并将其用于求解连续函数的 **最值问题**，（默认数学规划还带一些 Matlab 求解的函数）。

它的核心思想是利用群体中的 **个体对信息的共享** 使整个群体的运动在问题求解空间中产生从无序到有序的演化过程，从而获得问题的可行解。

## 概念

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507170357350.png)

gbest 可以为全体的信息，也可以为邻近的信息。

- 粒子：优化问题的候选解
- 位置：候选解所在的位置
- 速度：候选解移动的速度
- 适应度：评价粒子优劣的值，一般设置为目标函数值
- 个体最佳位置：单个粒子迄今为止找到的最佳位置
- 群体最佳位置：所有粒子迄今为止找到的最佳位置

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507170644228.png)

## 关键步骤

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507170720440.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507170902046.png)

第 d 步的速度 = 上一步速度 * 惯性 + 自我认知部分 + 社会认知部分

r1、r2 是 [0, 1] 上的随机数，c1、c2 学习因子取 2，w 惯性权重一般取 0.9。

### 权重改进

- 线性递减惯性权重

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507183714036.png)

```matlab
w_start = 0.9;
w_end = 0.4;
...
w = w_start - (w_start - w_end) * d / K;
```

- 自适应关系权重

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507183831944.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512194910668.png)

```matlab
w_max = 0.9;
w_min = 0.4;
...
f_i = fit(i);  % 取出第i个粒子的适应度
f_avg = sum(fit)/n;  % 计算此时适应度的平均值
f_min = min(fit); % 计算此时适应度的最小值
if f_i <= f_avg  
	if f_avg ~= f_min  % 如果分母为0，我们就干脆令w=w_min
		w = w_min + (w_max - w_min)*(f_i - f_min)/(f_avg - f_min);
    else
        w = w_min;
    end
else
    w = w_max;
end
```

- 随机惯性权重

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507184434122.png)

```matlab
w_max = 0.9;
w_min = 0.4;
sigma = 0.3; % 正态分布的随机扰动项的标准差（一般取0.2-0.5之间）
...
w = w_min + (w_max - w_min)*rand(1) + sigma*randn(1);
```

### 学习因子改进

个体学习因子 c1 和社会(群体)学习因子 c2 决定了粒子本身经验信息和其他粒子的经验信息对粒子运行轨迹的影响，其反映了粒子群之间的信息交流。设置 c1 较大的值，会使粒子过多地在自身的局部范围内搜索，而较大的 c2 的值，则又会促使粒子过早收敛到局部最优值。

- 压缩因子法

为了有效地控制粒子的飞行速度，使算法达到全局搜索与局部搜索两者间的有效平衡，Clerc 构造了引入收缩因子的 PSO 模型，采用了压缩因子，这种调整方法通过合适选取参数，可确保PSO算法的收敛性，并可取消对速度的边界限制。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507185005010.png)

```matlab
c1 = 2.05;  % 每个粒子的个体学习因子，也称为个体加速常数
c2 = 2.05;  % 每个粒子的社会学习因子，也称为社会加速常数
C = c1 + c2; 
fai = 2/abs((2-C-sqrt(C^2-4*C))); % 收缩因子
...
v(i,:) = fai * (w*v(i,:) + c1*rand(1)*(pbest(i,:) - x(i,:)) + c2*rand(1)*(gbest - x(i,:))); 
```

- 非对称学习因子

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507185516251.png)

```matlab
c1_ini = 2.5;  % 个体学习因子的初始值
c1_fin = 0.5;  % 个体学习因子的最终值
c2_ini = 1;  % 社会学习因子的初始值
c2_fin = 2.25;  % 社会学习因子的最终值
...
c1 = c1_ini + (c1_fin - c1_ini)*d/K;
c2 = c2_ini + (c2_fin - c2_ini)*d/K;
```

### 搜索终止条件

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507190056144.png)

```matlab
%% 改进：自动退出迭代循环
Count = 0; % 计数器初始化为0
max_Count = 30;  % 最大计数值初始化为30
tolerance = 1e-6;  % 函数变化量容忍度，取10^(-6)
...
delta_fit = abs(Obj_fun3(gbest) - Obj_fun3(tem));   % 计算相邻两次迭代适应度的变化量
if delta_fit < tolerance  % 判断这个变化量和“函数变化量容忍度”的相对大小，如果前者小，则计数器加1
	Count = Count + 1;
else
	Count = 0;
end   
if Count > max_Count  % 如果计数器的值达到了最大计数值
	break;  % 跳出循环
end
```

## 例题解决

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507171252968.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507171421720.png)

```matlab
function y = fun1(x)
    y = -(11*sin(x) + 7*cos(5*x));
end
%% Matlab 自带函数求解非线性函数最值问题
x0 = 0;
A = [];
b = [];
Aeq = [];
beq = [];
x_lb = -3;
x_ub = 3;
[x, fval] = fmincon(@fun1, x0, A, b, Aeq, beq, x_lb, x_ub)
fval = -fval

%% 粒子群法解
% 绘制图形
x = -3:0.01:3;
y = 11*sin(x) + 7*cos(5*x);
figure(1)
plot(x,y,'b-')
title('y = 11*sin(x) + 7*cos(5*x)')
hold on

%% 粒子群算法中的预设参数
n = 10; % 粒子数量
narvs = 1; % 变量个数
c1 = 2;  % 每个粒子的个体学习因子，也称为个体加速常数
c2 = 2;  % 每个粒子的社会学习因子，也称为社会加速常数
w = 0.9;  % 惯性权重
K = 50;  % 迭代的次数
vmax = 1.2; % 粒子的最大速度 (6/5)
x_lb = -3; % x的下界
x_ub = 3; % x的上界

%% 初始化粒子的位置和速度
x = zeros(n,narvs);
for i = 1: narvs
    x(:,i) = x_lb(i) + (x_ub(i)-x_lb(i))*rand(n,1);    % 随机初始化粒子所在的位置在定义域内
end
v = -vmax + 2*vmax .* rand(n,narvs);

%% 计算适应度
fit = zeros(n,1);
for i = 1:n
    fit(i) = Obj_fun1(x(i,:));
end
pbest = x; % 初始化这n个粒子迄今为止找到的最佳位置
ind = find(fit == max(fit), 1);
gbest = x(ind,:); % 定义所有粒子迄今为止找到的最佳位置

%% 在图上标上这n个粒子的位置用于演示
h = scatter(x, fit, 80, '*r');
fitnessbest = ones(K,1);
for d = 1:K
	for i = 1:n
		% 更新第i个粒子的速度
		v(i,:) = w*v(i,:) + c1*rand(1)*(pbest(i,:) - x(i,:)) + c2*rand(1)*(gbest - x(i,:));
		for j = 1: narvs
            if v(i,j) < -vmax(j)
                v(i,j) = -vmax(j);
            elseif v(i,j) > vmax(j)
                v(i,j) = vmax(j);
            end
        end
        
        % 更新第i个粒子的位置
        x(i,:) = x(i,:) + v(i,:);
        for j = 1: narvs
            if x(i,j) < x_lb(j)
                x(i,j) = x_lb(j);
            elseif x(i,j) > x_ub(j)
                x(i,j) = x_ub(j);
            end
        end
        
        % 重新计算第i个粒子的适应度
        fit(i) = Obj_fun1(x(i,:));
        if fit(i) > Obj_fun1(pbest(i,:))
            pbest(i,:) = x(i,:);
        end
        if  fit(i) > Obj_fun1(gbest)
        	gbest = pbest(i,:);
        end
	end
	
	% 更新第d次迭代得到的最佳的适应度
	fitnessbest(d) = Obj_fun1(gbest);
	pause(0.1)
	h.XData = x;
	h.YData = fit;
end

% 绘制出每次迭代最佳适应度的变化图
figure(2)
plot(fitnessbest)  
xlabel('迭代次数');
disp('最佳的位置是：'); disp(gbest)
disp('此时最优值是：'); disp(Obj_fun1(gbest))
```

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507183011706.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507183034830.png)

```matlab
function y = Obj_fun2(x)  
    y = x(1)^2 + x(2)^2 - x(1)*x(2) - 10*x(1) - 4*x(2) + 60;
end
%% Matlab 自带函数求解非线性函数
x0 = [0 0];  
A=[]; b=[];
Aeq=[]; beq=[];
x_lb = [-15 -15];
x_ub = [15 15];
[x,fval] = fmincon(@Obj_fun2,x0,A,b,Aeq,beq,x_lb,x_ub)

%% 绘制函数的图形
x1 = -15:1:15;
x2 = -15:1:15;
[x1, x2] = meshgrid(x1,x2);
y = x1.^2 + x2.^2 - x1.*x2 - 10*x1 - 4*x2 + 60;
mesh(x1, x2, y)
xlabel('x1');  ylabel('x2');  zlabel('y');
axis vis3d % 冻结屏幕高宽比，使得一个三维对象的旋转不会改变坐标轴的刻度显示
hold on 

%% 粒子群算法中的预设参数
n = 30;
narvs = 2;
c1 = 2;
c2 = 2;
w = 0.9;
K = 100;
vmax = [6 6];
x_lb = [-15 -15];
x_ub = [15 15];

%% 初始化粒子的位置和速度
x = zeros(n,narvs);
for i = 1: narvs
    x(:,i) = x_lb(i) + (x_ub(i)-x_lb(i))*rand(n,1);
end
v = -vmax + 2*vmax .* rand(n,narvs);

%% 计算适应度(注意，因为是最小化问题，所以适应度越小越好)
fit = zeros(n,1);
for i = 1:n
    fit(i) = Obj_fun2(x(i,:));
end 
pbest = x;
ind = find(fit == min(fit), 1);
gbest = x(ind,:)

h = scatter3(x(:,1),x(:,2),fit,'*r');
%% 迭代K次来更新速度与位置
fitnessbest = ones(K,1);
for d = 1:K
    for i = 1:n 
    	% 更新第i个粒子的速度
        v(i,:) = w*v(i,:) + c1*rand(1)*(pbest(i,:) - x(i,:)) + c2*rand(1)*(gbest - x(i,:));  
        for j = 1: narvs
            if v(i,j) < -vmax(j)
                v(i,j) = -vmax(j);
            elseif v(i,j) > vmax(j)
                v(i,j) = vmax(j);
            end
        end
        
        % 更新第i个粒子的位置
        x(i,:) = x(i,:) + v(i,:); 
        for j = 1: narvs
            if x(i,j) < x_lb(j)
                x(i,j) = x_lb(j);
            elseif x(i,j) > x_ub(j)
                x(i,j) = x_ub(j);
            end
        end
        
        % 重新计算第i个粒子的适应度
        fit(i) = Obj_fun2(x(i,:));
        if fit(i) < Obj_fun2(pbest(i,:))
           pbest(i,:) = x(i,:);
        end
        if fit(i) < Obj_fun2(gbest)
            gbest = pbest(i,:);
        end
    end
    fitnessbest(d) = Obj_fun2(gbest);
    pause(0.1)
    h.XData = x(:,1);
    h.YData = x(:,2);
    h.ZData = fit;
end

% 绘制出每次迭代最佳适应度的变化图
figure(2) 
plot(fitnessbest)  
xlabel('迭代次数');
disp('最佳的位置是：'); disp(gbest)
disp('此时最优值是：'); disp(Obj_fun2(gbest))
```

## Matlab 工具箱

Matlab 中 `particleswarm` 函数采用的是自适应的邻域模式，只将周围部分粒子视为领域粒子，这种模式使得粒子群可以被分割为多个不同的子群体，有利于在多个区域进行搜索，避免陷入局部最优。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507191129731.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507191200603.png)

## 进阶

粒子群可以解决 非线性约束 问题，在适应度函数上构造 **惩罚项** , 对违反约束的情况进行惩罚, 将有约束的优化问题转化为无约束的优化问题。

粒子群算法最初提出来用于连续空间的优化，从核心运动公式上看，定义的都是连续的变量，对于组合优化问题，不适于求解，需要重新定义粒子群算法的运动公式和符号，或者采用其他启发式算法（比如：模拟退火算法）。

粒子群算法不需要给初始值，只需要给一个搜索的范围。

### 方程组求解

对于方程组求解，可以合并构造求最小值为 0。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507192036403.png)

```matlab
function F = my_fun(x)
    F(1) = abs(x(1)+x(2))-abs(x(3));
    F(2) = x(1) * x(2) * x(3) + 18;
    F(3) = x(1)^2*x(2)+3*x(3);
end
%% vpasolve函数
syms x1 x2 x3
eqn =  [abs(x1+x2)-abs(x3)  == 0, x1*x2*x3+18 == 0, x1^2*x2+3*x3 == 0]
[x1, x2, x3] = vpasolve(eqn, [x1, x2, x3], [0 0 0])  
[x1, x2, x3] = vpasolve(eqn, [x1, x2, x3], [1 1 1])  % 换一个初始值试试

%% fsolve函数
x0 = [0,0,0];  % 初始值
x = fsolve(@my_fun, x0)
x0 = [1,1,1];  % 初始值
format long g
x = fsolve(@my_fun,x0)

function f = Obj_fun(x)
    f1= abs(x(1)+x(2))-abs(x(3)) ;
    f2= x(1) * x(2) * x(3) + 18;
    f3= x(1)^2 * x(2) + 3*x(3);
    f = abs(f1) + abs(f2) + abs(f3);
end
%% 粒子群算法，求最小值到0
narvs = 3;
% 使用粒子群算法，不需要指定初始值，只需要给定一个搜索的范围
lb = -10*ones(1,3);  ub = 10*ones(1,3);
options = optimoptions('particleswarm','FunctionTolerance',1e-12, 'MaxStallIterations',100,'MaxIterations',20000, 'SwarmSize',100);
[x, fval] = particleswarm(@Obj_fun, narvs, lb, ub, options)
```

### 多元函数拟合

cftool 拟合工具箱只能对一元函数和二元函数进行拟合。

最小二乘法拟合的本质，求最小值问题。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507192447225.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507192510192.png)

```matlab
function f = Obj_fun(k)
    global x y;
    y_hat = exp(-k(1)*x(:,1)) .* sin(k(2)*x(:,2)) + x(:,3).^2;  % 拟合值
    f = sum((y - y_hat) .^ 2);
end

global x y;  % 将x和y定义为全局变量（方便在子函数中直接调用，要先声明）
load data_x_y  % 数据集内里面有x和y两个变量
k0 = [0 0];  % 这个初始值的选取需要尝试
lb = []; ub = [];
[k, fval] = fmincon(@Obj_fun,k0,[],[],[],[],lb,ub)  

%% 求解无约束非线性函数的最小值的两个函数
[k, fval] = fminsearch(@Obj_fun,k0)   % Nelder-Mead单纯形法求解最小值，适用于解决不可导或求导复杂的函数优化问题
[k, fval] = fminunc(@Obj_fun,k0)  % 拟牛顿法求解无约束最小值，适用于解决求导容易的函数优化问题

%% 计算拟合值和实际值的相对误差
y_hat = exp(-k(1)*x(:,1)) .* sin(k(2)*x(:,2)) + x(:,3).^2;  % 计算拟合值
res_rate = abs(y - y_hat) ./ y;  %  相对误差
plot(res_rate) % 每个样本对应的相对误差
mean(res_rate) % 平均相对误差

%% 非线性最小二乘拟合函数lsqcurvefit
function y_hat = fit_fun(k,x)
    y_hat = exp(-k(1)*x(:,1)) .* sin(k(2)*x(:,2)) + x(:,3).^2;  % 返回的函数就是我们的拟合值
end
k0 = [0 0]; % 初始值
lb = []; ub = [];
[k, fval] = lsqcurvefit(@fit_fun,k0,x,y,lb,ub)
% Choose between 'trust-region-reflective' (default) and 'levenberg-marquardt'.
options= optimoptions('lsqcurvefit','Algorithm','levenberg-marquardt');
[k, fval] = lsqcurvefit(@fit_fun,k0,x,y,lb,ub,options)

%% 粒子群法
function f = Obj_fun(k)
    global x y;  % 在子函数中使用全局变量前也需要声明下
    y_hat = exp(-k(1)*x(:,1)) .* sin(k(2)*x(:,2)) + x(:,3).^2;
    f = sum((y - y_hat) .^ 2);
end
narvs = 2;
lb = [-10 -10];  ub = [10 10];  
[k, fval] = particleswarm(@Obj_fun,narvs,lb,ub) 
% 使用粒子群算法后再利用fmincon函数混合求解
options = optimoptions('particleswarm','HybridFcn',@fmincon);
[k,fval] = particleswarm(@Obj_fun,narvs,lb,ub,options)
```

### 微分方程拟合参数选取

为微分方程选取最好的拟合参数，粒子群作为最外层搜索框架来寻找参数。

网格搜索，确定范围，枚举参数，逐步缩小，如果我们有多个要搜索的变量，网格搜索法就很难办了，多重循环会大大增加搜索时间。

粒子群算法计算的结果具有随机性，结果可能会变换，可以多次运行取一个最好的结果。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507193816758.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507194051903.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507200152554.png)

```matlab
function dx=SIR_fun(t,x,beta,gamma)   
    dx = zeros(3,1);
    C = x(1)+x(2);
    dx(1) = - beta*x(1)*x(2)/C;  
    dx(2) = beta*x(1)*x(2)/C - gamma*x(2);
    dx(3) = gamma*x(2); 
end

load mydata.mat  % 导入数据（共三列，分别是S,I,R的数量）
n = size(mydata,1);  % 一共有多少行数据
true_s = mydata(:,1);   
true_i = mydata(:,2);
true_r = mydata(:,3);
figure(1)
plot(1:n,true_i,'b-',1:n,true_r,'g-') % 单独画出真实的I和R的数量
hold on  % 等会接着在这个图形上面画图

%% 网格法搜索（枚举法） 地毯式搜索
BETA = 0.1:0.01:0.3;  % 估计一个BETA所在的范围
GAMMA = 0.01:0.001:0.1;  % 估计一个GAMMA所在的范围
n1 = length(BETA);
n2 = length(GAMMA);
SSE = zeros(n1,n2);  % 初始化残差平方和矩阵
for i = 1:n1
    for j = 1:n2
        beta = BETA(i);
        gamma = GAMMA(j);
        [t,p]=ode45(@(t,x) SIR_fun(t,x,beta,gamma), [1:n],[true_s(1) true_i(1) true_r(1)]);
        p = round(p);
        sse = sum((true_s - p(:,1)).^2  + (true_i -  p(:,2)).^2  + (true_r - p(:,3)).^2);
        SSE(i,j) = sse;
    end
end
% 画出SSE这个矩阵的热力图
figure(2) 
pcolor(GAMMA,BETA,SSE)  % 注意，这里GAMMA和BETA的顺序不能反了（类似于更新13里面的mesh函数的用法）
colorbar
min_sse = min(min(SSE));
[r,c] = find(SSE == min_sse,1);  % find后面加了一个1，表示返回第一个最小值所在的行和列的序号
beta = BETA(r)
gamma = GAMMA(c)

figure(3)
plot(1:n,true_i,'b-',1:n,true_r,'g-') % 单独画出真实的I和R的数量
hold on
[t,p]=ode45(@(t,x) SIR_fun(t,x,beta,gamma), [1:n],[true_s(1) true_i(1) true_r(1)]);
p = round(p);
plot(1:n,p(:,2),'b--',1:n,p(:,3),'g--') 
legend('I','R','拟合的I','拟合的R')
hold off

function f = Obj_fun(h)  
    global true_s true_i true_r n
    beta = h(1);
    gamma = h(2);
    [t,p]=ode45(@(t,x) SIR_fun(t,x,beta,gamma), [1:n],[true_s(1) true_i(1) true_r(1)]);   
    p = round(p);
    f = sum((true_s - p(:,1)).^2  + (true_i -  p(:,2)).^2  + (true_r - p(:,3)).^2);
end

%% 粒子群算法来求解
lb = [0 0]; 
ub = [1 1];  
nvars = 2;
options = optimoptions('particleswarm','Display','iter','SwarmSize',100,'PlotFcn','pswplotbestf');
[h, fval] = particleswarm(@Obj_fun,nvars,lb,ub,options)  % h就是要优化的参数，fval是目标函数值

beta = h(1);  % 易感染者与已感染者接触且被传染的强度
gamma = h(2);  % 康复率
[t,p]=ode45(@(t,x) SIR_fun(t,x,beta,gamma), [1:n],[true_s(1) true_i(1) true_r(1)]);   
p = round(p);  % 对p进行四舍五入(人数为整数)
sse = sum((true_s - p(:,1)).^2  + (true_i -  p(:,2)).^2  + (true_r - p(:,3)).^2)  % 计算残差平方和

% 真实的人数和拟合的人数放到一起看看
N = 27; % 计算N天
[t,p]=ode45(@(t,x) SIR_fun(t,x,beta,gamma), [1:N],[true_s(1) true_i(1) true_r(1)]);   
p = round(p);  % 对p进行四舍五入(人数为整数)
figure(4)
plot(1:n,true_i,'b-',1:n,true_r,'g-') 
hold on
plot(1:N,p(:,2),'b--',1:N,p(:,3),'g--')
legend('I','R','拟合的I','拟合的R')
```

参数进一步假设参数为线性变化过程：

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507200250193.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210507200306931.png)

```matlab
function dx=SIR_fun(t,x,beta1,beta2,a,b)  
    % beta1 : t<=15时，易感染者与已感染者接触且被传染的强度
    % beta2 : t>15时，易感染者与已感染者接触且被传染的强度
    % a : 康复率gamma = a+bt
    % b : 康复率gamma = a+bt
    if t <=15
        beta = beta1;
    else
        beta = beta2;
    end
    gamma = a + b * t;  
    dx = zeros(3,1);
    C = x(1)+x(2);
    dx(1) = - beta*x(1)*x(2)/C;  
    dx(2) = beta*x(1)*x(2)/C - gamma*x(2);
    dx(3) = gamma*x(2); 
end
function f = Obj_fun(h)  
    global true_s  true_i  true_r n 
    beta1 = h(1);
    beta2 = h(2);
    a = h(3);
    b = h(4);
    [t,p]=ode45(@(t,x) SIR_fun(t,x,beta1,beta2,a,b) , [1:n],[true_s(1) true_i(1) true_r(1)]);   
    p = round(p);
    f = sum((true_s - p(:,1)).^2  + (true_i -  p(:,2)).^2  + (true_r - p(:,3)).^2);
end

% 粒子群算法来求解
% beta1,beta2,a,b
% 给定参数的搜索范围（根据题目来给），后期可缩小范围
lb = [0 0 -1 -1]; 
ub = [1 1 1 1];  
options = optimoptions('particleswarm','Display','iter','SwarmSize',200);
[h, fval] = particleswarm(@Obj_fun, 4, lb, ub, options)
beta1 = h(1);  % t<=15时，易感染者与已感染者接触且被传染的强度
beta2 = h(2);  % t>15时，易感染者与已感染者接触且被传染的强度
a = h(3); % 康复率gamma = a+bt
b = h(4);  % 康复率gamma = a+bt
[t,p]=ode45(@(t,x) SIR_fun(t,x,beta1,beta2,a,b), [1:n],[true_s(1) true_i(1) true_r(1)]);   
p = round(p);
N = 27; % 计算N天
[t,p]=ode45(@(t,x) SIR_fun(t,x,beta1,beta2,a,b), [1:N],[true_s(1) true_i(1) true_r(1)]);   
p = round(p);
figure(4)
plot(1:n,true_i,'b-',1:n,true_r,'g-') 
hold on
plot(1:N,p(:,2),'b--',1:N,p(:,3),'g--') 
legend('I','R','拟合的I','拟合的R')
```

# 模拟退火算法

又称 SA 算法，基于金属模拟退火机理，能够以随机搜索技术从概率意义上找到目标函数的全局最值点。

## 与粒子群算法对比

不仅能够处理连续优化问题，也能方便的处理组合优化问题。

对参数的选取至关重要。

面对不同的问题，需要设计不同的退火过程，不同过程得到的准确度和效率可能有较大差别。

## 引入

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512170256977.png)

爬山法的局限是特别容易找到局部最优解，模拟退火算法能以一定的概率接受一个比当前解要差的解，跳出局部区域。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512170513793.png)

## 关键步骤

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512171433178.png)

### 概率设置

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512181751107.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512171650540.png)

### 搜索终止条件

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512182034071.png)

## 例题解决

新解的设置随着具体问题具体分析：

### 例1 求给定函数最值

![image-20210512181413884](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512181413884.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512183822688.png)

```matlab
function y = Obj_fun1(x)
    y = 11*sin(x) + 7*cos(5*x);
end

f = @(x) 11*sin(x) + 7*cos(5*x);
figure
fplot(f, [-3 3])
hold on  % 不关闭图形，继续在上面画图

narvs = 1; % 变量个数
T0 = 100; % 初始温度
T = T0; 
maxgen = 200;  % 最大迭代次数
Lk = 100;  % 每个温度下的迭代次数
alfa = 0.95;  % 温度衰减系数
x_lb = -3; % x的下界
x_ub = 3; % x的上界

%  随机生成一个初始解
x0 = zeros(1,narvs);
for i = 1: narvs
    x0(i) = x_lb(i) + (x_ub(i) - x_lb(i)) * rand(1);    
end

y0 = Obj_fun1(x0);
h = scatter(x0, y0, '*r');

max_y = y0; % 初始化找到的最佳的解对应的函数值为y0
MAXY = zeros(maxgen,1); % 记录每一次外层循环结束后找到的max_y

for iter = 1:maxgen
    for i = 1:Lk  % 内循环，在每个温度下开始迭代
        y = randn(1, narvs); % 生成 1 行 narvs 列的 N(0,1) 随机数
        z = y / sqrt(sum(y.^2));
        x_new = x0 + z * T;
        for j = 1: narvs
            if x_new(j) < x_lb(j)
                r = rand(1);
                x_new(j) = r * x_lb(j) + (1-r) * x0(j);
            elseif x_new(j) > x_ub(j)
                r = rand(1);
                x_new(j) = r * x_ub(j) + (1-r) * x0(j);
            end
        end
        x1 = x_new;
        y1 = Obj_fun1(x1);
        if y1 > y0
            x0 = x1;
            y0 = y1;
        else
            p = exp(-(y0 - y1)/T);
            if rand(1) < p
                x0 = x1;
                y0 = y1;
            end
        end
        
        if y0 > max_y
            max_y = y0;
            best_x = x0;
        end
    end
    
    MAXY(iter) = max_y;
    T = alfa * T;
    pause(0.01)
    h.XData = x0;
    h.YData = Obj_fun1(x0);
end

disp('最佳的位置是：'); disp(best_x)
disp('此时最优值是：'); disp(max_y)
pause(0.5)
h.XData = [];  h.YData = [];
scatter(best_x,max_y,'*r');

figure
plot(1:maxgen, MAXY, 'b-');
xlabel('迭代次数');
ylabel('y的值');
```

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512183859684.png)

```matlab
function y = Obj_fun2(x)
    y = x(1)^2 + x(2)^2 - x(1)*x(2) - 10*x(1) - 4*x(2) + 60;
end

figure 
x1 = -15:1:15;
x2 = -15:1:15;
[x1,x2] = meshgrid(x1,x2);
y = x1.^2 + x2.^2 - x1.*x2 - 10*x1 - 4*x2 + 60;
mesh(x1,x2,y)
xlabel('x1');  ylabel('x2');  zlabel('y'); 
axis vis3d 
hold on 

narvs = 2; 
T0 = 100; 
T = T0; 
maxgen = 200; 
Lk = 100; 
alfa = 0.95; 
x_lb = [-15 -15]; 
x_ub = [15 15]; 

x0 = zeros(1,narvs);
for i = 1: narvs
    x0(i) = x_lb(i) + (x_ub(i)-x_lb(i))*rand(1);    
end
y0 = Obj_fun2(x0);
h = scatter3(x0(1),x0(2),y0,'*r'); 

min_y = y0; 
MINY = zeros(maxgen,1);

for iter = 1 : maxgen 
    for i = 1 : Lk 
        y = randn(1,narvs); 
        z = y / sqrt(sum(y.^2));
        x_new = x0 + z*T; 
 
        for j = 1: narvs
            if x_new(j) < x_lb(j)
                r = rand(1);
                x_new(j) = r*x_lb(j)+(1-r)*x0(j);
            elseif x_new(j) > x_ub(j)
                r = rand(1);
                x_new(j) = r*x_ub(j)+(1-r)*x0(j);
            end
        end
        x1 = x_new; 
        y1 = Obj_fun2(x1);
        if y1 < y0
            x0 = x1; 
            y0 = y1;
        else
            p = exp(-(y1 - y0)/T);
            if rand(1) < p 
                x0 = x1;  
                y0 = y1;
            end
        end

        if y0 < min_y 
            min_y = y0; 
            best_x = x0; 
        end
    end
    MINY(iter) = min_y; %
    T = alfa*T;
    pause(0.02)
    h.XData = x0(1);
    h.YData = x0(2);
    h.ZData = Obj_fun2(x0);
end

disp('最佳的位置是：'); disp(best_x)
disp('此时最优值是：'); disp(min_y)

pause(0.5) 
h.XData = [];  h.YData = [];  h.ZData = [];  % 将原来的散点删除
scatter3(best_x(1), best_x(2), min_y,'*r');  % 在最小值处重新标上散点

figure
plot(1:maxgen,MINY,'b-');
xlabel('迭代次数');
ylabel('y的值');
```

### 例2 旅行商问题

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512185127265.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512185226456.png)



![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512185320870.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512185348249.png)

```matlab
function  result =  calculate_tsp_d(path,d)
    n = length(path);
    result = 0;
    for i = 1:n-1  
        result = d(path(i),path(i+1)) + result;
    end   
    result = d(path(1), path(n)) + result;
end

function path1 = gen_new_path(path0)
    % path0: 原来的路径
    n = length(path0);
    % 随机选择两种产生新路径的方法
    p1 = 0.33;  
    p2 = 0.33;
    r = rand(1);
    if  r < p1 % 使用交换法产生新路径的概率
        c1 = randi(n); 
        c2 = randi(n);
        path1 = path0;
        path1(c1) = path0(c2);
        path1(c2) = path0(c1);
    elseif r < p1 + p2 % 使用移位法产生新路径
        c1 = randi(n); 
        c2 = randi(n);
        c3 = randi(n);
        sort_c = sort([c1 c2 c3]);  % 对c1 c2 c3从小到大排序
        c1 = sort_c(1);  c2 = sort_c(2);  c3 = sort_c(3);
        tem1 = path0(1:c1-1);
        tem2 = path0(c1:c2);
        tem3 = path0(c2+1:c3);
        tem4 = path0(c3+1:end);
        path1 = [tem1 tem3 tem2 tem4];
    else  % 使用倒置法产生新路径
        c1 = randi(n);
        c2 = randi(n);
        
        if c1 > c2
            tem = c2;
            c2 = c1;
            c1 = tem;
        end
        
        tem1 = path0(1:c1-1);
        tem2 = path0(c1:c2);
        tem3 = path0(c2+1:end);
        path1 = [tem1 fliplr(tem2) tem3];   % 矩阵的左右对称翻转 fliplr，上下对称翻转 flipud
    end
end

rng('shuffle')  % 控制随机数的生成，否则每次打开matlab得到的结果都一样
% 38个城市，TSP数据集网站(http://www.tsp.gatech.edu/world/djtour.html) 上公测的最优结果6656。
coord = [11003.611100,42102.500000;11108.611100,42373.888900;11133.333300,42885.833300;11155.833300,42712.500000;11183.333300,42933.333300;11297.500000,42853.333300;11310.277800,42929.444400;11416.666700,42983.333300;11423.888900,43000.277800;11438.333300,42057.222200;11461.111100,43252.777800;11485.555600,43187.222200;11503.055600,42855.277800;11511.388900,42106.388900;11522.222200,42841.944400;11569.444400,43136.666700;11583.333300,43150.000000;11595.000000,43148.055600;11600.000000,43150.000000;11690.555600,42686.666700;11715.833300,41836.111100;11751.111100,42814.444400;11770.277800,42651.944400;11785.277800,42884.444400;11822.777800,42673.611100;11846.944400,42660.555600;11963.055600,43290.555600;11973.055600,43026.111100;12058.333300,42195.555600;12149.444400,42477.500000;12286.944400,43355.555600;12300.000000,42433.333300;12355.833300,43156.388900;12363.333300,43189.166700;12372.777800,42711.388900;12386.666700,43334.722200;12421.666700,42895.555600;12645.000000,42973.333300];
n = size(coord, 1);  % 城市的数目


figure 
plot(coord(:,1), coord(:,2), 'o');
hold on

d = zeros(n);
for i = 2:n  
    for j = 1:i  
        coord_i = coord(i,:);   x_i = coord_i(1);     y_i = coord_i(2);  % 城市i的横坐标为x_i，纵坐标为y_i
        coord_j = coord(j,:);   x_j = coord_j(1);     y_j = coord_j(2);  % 城市j的横坐标为x_j，纵坐标为y_j
        d(i,j) = sqrt((x_i-x_j)^2 + (y_i-y_j)^2);   % 计算城市i和j的距离
    end
end
d = d+d'; % 生成距离矩阵的对称的一面


T0 = 1000;
T = T0;
maxgen = 1000;
Lk = 500;
alpfa = 0.95;

%%  随机生成初始解
path0 = randperm(n);  % 生成一个 1-n 的随机打乱的序列作为初始的路径
result0 = calculate_tsp_d(path0, d);

min_result = result0;
RESULT = zeros(maxgen,1);

for iter = 1:maxgen 
    for i = 1:Lk
        path1 = gen_new_path(path0);  % 生成新的路径
        result1 = calculate_tsp_d(path1,d); % 计算新路径的距离

        if result1 < result0    
            path0 = path1;
            result0 = result1; 
        else
            p = exp(-(result1 - result0)/T);
            if rand(1) < p
                path0 = path1;
                result0 = result1; 
            end
        end

        if result0 < min_result
            min_result = result0; 
            best_path = path0;
        end
    end
    RESULT(iter) = min_result;
    T = alpfa*T;      
end


disp('最佳的方案是：'); disp(mat2str(best_path))
disp('此时最优值是：'); disp(min_result)


best_path = [best_path,best_path(1)];   % 生成一个封闭的图形
n = n+1;
for i = 1:n-1 
    j = i+1;
    coord_i = coord(best_path(i),:);   x_i = coord_i(1);     y_i = coord_i(2); 
    coord_j = coord(best_path(j),:);   x_j = coord_j(1);     y_j = coord_j(2);
    plot([x_i,x_j],[y_i,y_j],'-b') 
    hold on
end

figure
plot(1:maxgen,RESULT,'b-');
xlabel('迭代次数');
ylabel('最短路径');

```

### 例3 买书问题

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512191154391.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512191125701.png)



```matlab
function way1 = gen_new_way(way0, s, b)
    index =  randi([1, b],1) ;  % 看哪一本书要更换书店购买
    way1 = way0;
    way1(index) = randi([1, s],1);  % 第index本书换一个书店购买   
end

function  money =  calculate_money(way,freight,M,b)
    index = unique(way); 
    money = sum(freight(index)); % 计算买书花费的运费
    for i = 1:b 
        money = money + M(way(i), i);  
    end
end

rng('shuffle')
load book_data
[s, b] = size(M);  % s是书店的数量，b是要购买的书的数量

T0 = 1000;  
T = T0;
maxgen = 500; 
Lk = 200;
alfa = 0.95;

%%  随机生成一个初始解
way0 = randi([1, s],1,b); % 在1-s 这些整数中随机抽取一个1*b的向量，表示这b本书分别在哪家书店购买
money0 = calculate_money(way0, freight, M, b); 

min_money = money0;
MONEY = zeros(maxgen,1);

for iter = 1:maxgen
    for i = 1:Lk
        way1 = gen_new_way(way0,s,b); 
        money1 = calculate_money(way1,freight,M,b);
        if money1 < money0  
            way0 = way1;
            money0 = money1;
        else
            p = exp(-(money1 - money0)/T);
            if rand(1) < p   
                way0 = way1;
                money0 = money1;
            end
        end

        if money0 < min_money  
            min_money = money0;  
            best_way = way0;  
        end
    end
    MONEY(iter) = min_money; 
    T = alfa*T; 
end

disp('最佳的方案是：'); disp(mat2str(best_way))
disp('此时最优值是：'); disp(min_money)

figure
plot(1:maxgen,MONEY,'b-');
xlabel('迭代次数');
ylabel('最小花费');

```

## Matlab 工具箱

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512192158999.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512192230493.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512192440424.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210512192614752.png)

其他设置分别是设置模拟退火过程函数（Matlab 自实现中间还有部分升温过程，避免局部最优）、温度下降函数、初始温度。

跟大多数优化算法一样，用到随机数，每次运行可能会有差异，不一定到达全局最优解。

# 遗传算法

又称 GA 算法，使用软件：Matlab。

## 概念

基于生物进化规律，即物竞天择，适者生存演变而来的一种优化算法。

基因：每个解的组成分量

个体（染色体）：待求解优化问题的一个解

种群：由很多个体组成的群体

交叉：从选择好的个体中两两配对，并按某种方式互换基因以产生下一代

选择：从当前的种群中选择比较好的个体，使之有机会将其基因遗传到下一代

变异：对种群中的一些个体有一定概率发生变异，产生新个体。

## 关键步骤

### 编码

- 二进制编码

  二进制编码，长度 $L$ 为 $\log_2{(\frac{b-a}{eps} +1)}$，$(a,b)$ 是自变量范围，$eps$ 是要求的精度

  二进制数据解码，$x=a+(b-a)\times X / (2^L-1)$，$X$ 代表二进制数据的值

  存在多个自变量时，编码长度为每个自变量编码长度之和

- 实值编码

  个体编码长度即为决策变量个数，需要限制基因值的范围。

  比较适合表示范围较大数，精度要求高、较大空间的遗传搜索。

```matlab
function real = decode(pop, lb, ub)
    col = size(pop, 2);
    for j = col:-1:1
        temp(j) = 2^(j-1) * pop(j);
    end
    temp = sum(temp);
    real = lb + (ub - lb) * temp / (2^col - 1);
end
```

### 适应度函数

即对于最优化问题，求全局最大值或最小值，会 **直接影响** 到遗传算法的收敛速度及能否找到最优解：

- 直接变换：

对于求最大值：
$$
F(x)=\left\{
\begin{array}{rcl}
f(x)+Cmin, & { f(x) + Cmin > 0}\\
0,  & {f(x) + Cmin \leq 0}\\
\end{array} \right.
$$
对于求最小值：
$$
F(x)=\left\{
\begin{array}{rcl}
-f(x)+Cmax, & { f(x) < Cmax}\\
0,  & {f(x) \geq Cmax}\\
\end{array} \right.
$$

- 线性变换1：

$F(x)=af(x)+b$

 $f_{min},f_{max}$ 为当前种群中的最小值或最大值，$\xi$ 为一个较小的数，可使种群中最差的个体仍然有繁殖的机会。

对于求最大值：$a=1,b=-f_{min}+\xi$，对于求最小值：$a=-1,b=f_{max}+\xi$

* 线性变换2：

$C$ 为常数，常取 2 或 1.5

若 $f_{min} > \frac{C f_{avg}-f_{max}}{C-1}$，$a = \frac{C-1}{f_{max}-f_{avg}}f_{avg}, b = \frac{f_{max}-Cf_{avg}}{f_{max}-f_{avg}}f_{avg}$

否则，$a = \frac{f_{avg}}{f_{avg}-f_{min}}, b = \frac{f_{avg}f_{min}}{f_{avg}-f_{min}}$

- 线性动态变换：

对于求最大值：$a=1,b=-f_{min}+\xi^k$，$\xi^k=\xi^{k-1} \times r, r \in[0.9,0.99]$，随着时间变化 $\xi$ 减小。

- 指数变换：

$F(x)=e^{-\alpha f(x)}$

保证了适应度函数非负性，若原问题求最大值，需要将目标函数乘上 -1，$\alpha$ 取值越大，变换后适应度差距越大。

```matlab
function fval = objfun(x)
    fval = 11 * sin(6 * x) + 7 * cos(5 * x);
end

function fitvalue = fitnessfun(x)
    global M ftype
    fval = objfun(x);

    switch ftype
        case 1 % 直接转换
            Cmin = 0.01;
            r = size(x, 1);
            for i = 1:r
               fval = objfun(x(i,:));
               if fval + Cmin > 0
                    fitvalue(i) = fval + Cmin;
               else
                    fitvalue(i) = 0;
               end
            end
        case 2 % 线性变换1
            kesai = 0.1;
            fmin = min(fval);
            fitvalue = fval - fmin + kesai;
        case 3 % 线性变换2
            C = 1.5;
            fmin = min(fval);
            fmax = max(fval);
            favg = sum(fval) / size(x, 1);
            if fmin < (C * favg - fmax) / (C - 1)
                a = (C - 1) * favg / (fmax - favg);
                b = (fmax - C * favg) * favg / (fmax - favg);
            else
                a = favg / (favg - fmin);
                b = favg * fmin / (favg - fmin);
            end
            fitvalue = a * fval + b;
        case 4 % 线性动态变换
            c = 0.9 + (0.099) * rand;
            M = M * c;
            fmin = min(fval);
            fitvalue = fval - fmin + M;
        case 5 % 指数变换
            alpha = 0.5;
            fitvalue = exp(alpha * fval);
    end
end
```

### 选择

- 轮盘赌选择法
  1.  计算各个体适应度 $f_i$
  2.  每个个体被选中的概率 $p_i=\frac{f_i}{\sum{f_i}}$，以及累积概率 $P_i$
  3.  随机产生 [0 1] 之间的一个随机数 $r$
  4.  依次比较累积概率与 $r$ 的值，选中第一个大于 $r$ 的值

- 排序选择

  1.  计算各个体适应度 $f_i$
  2.  按照适应度从大到小排序
  3.  定义最好的个体选择概率为 $q$ 
  4.  第 $i$ 个个体被选中的概率为 $p_i = \frac{q(1-q)^{i-1}}{1-(1-q)^n}$，$n$ 为种群大小 

  该算法早期时，个体适应度差别较大，经过几代后特优个体数目会越来越多，冲淡群体多样性。

- 最优保存（精英保存）

  由于遗传操作的随机性，当前种群中适应度最好的个体也可能被破坏掉，降低群体平均适应度，影响遗传算法的运行效率和收敛速度，所以将适应度最好的个体保留到下一代群体中。

  但是，这样也会让某个局部最优个体不易被淘汰掉反而快速扩展，从而使得算法的全局搜索能力不强，需要配合其他选择操作方法使用。

  1.  计算各个体适应度 $f_i$
  2.  找出最优和最差个体
  3.  比较最优个体和历史最优个体，更新历史最优个体
  4.  用历史最优个体替换本次最差个体

  除了保留单个最优个体，也可以保留多个最优个体，这种方法称为 *稳态复制*。

- 锦标赛选择

  每次先从种群中取出一定数量的个体，然后再选择其中最好的一个进入子代种群，重复该步骤直到达到原来的种群规模。

  1.  确定每次选择的个体数量 $sn$, 可以是固定值也可以是百分比，一般取 2
  2.  从种群中等概率选取 $sn$ 个个体，选取适应度最好的一个个体
  3.  重复该步骤，直到新个体构成一个新的种群

  选择的力度取决于 $sn$ 大小, $sn$ 越大，选出优胜者的适应度一般越大。

- 确定式采样选择

  无回放余数随机选择，其基本思想是按照一种 **确定** 的方式来进行选择，可保证适应度较大的一些个体能够被保留在下一代群体中。

  1.  确定种群中每个个体在下一代中的生存期望数目 $N_i=n\frac{f_i}{\sum{f_i}}$
  2.  先用 $N_i$ 的整数部分确定各个对应个体在下一代群体中的生成数目 $\sum{[N_i]}$
  3.  再根据 $N_i$ 的小数部分对个体进行降序排序，顺序取前 $n - \sum{[N_i]}$ 个个体加入到下一代群体中。

```matlab
function [dad, mom] = selection(pop, fitvalue, type)
    global q sn;
    row = size(pop, 1);
    
    switch type
        case 1 % 普通轮盘赌
            % 计算累加概率
            PP = cumsum(fitvalue ./ sum(fitvalue));
            for i = 1:row
                r = rand;
                % 父代由轮盘赌选取，母代随机选取。如果没有母代，父代第 1 个和第 2 个进行交叉...
                for j = 1:row
                    if r <= PP(j)
                        dad(i, :) = pop(j, :);
                        break
                    end
                end
                mom(i, :) = pop(randi([1 row]), :);
            end
        case 2 % 排序选择
            [~, Sindex] = sort(fitvalue, 'descend');
            pop = pop(Sindex, :); % 重新排序种群
            P = q * (1 - q) .^ ((1:row) - 1) / (1 - (1-q)^row);
            PP = cumsum(P);
            for i = 1:row
                r = rand;
                for j = 1:row
                    if r <= PP(j)
                        dad(i, :) = pop(j, :);
                        break
                    end
                end
                mom(i, :) = pop(randi([1 row]), :);
            end
        case 3 % 锦标赛选择
            for i = 1:row
                r = randi([1 row], sn, 1);
                [~, bestindex] = max(fitvalue(r));
                dad(i, :) = pop(r(bestindex), :);
                mom(i, :) = pop(randi([1 row]), :);
            end
        case 4 % 确定式采样选择
            Ni = row * fitvalue / (sum(fitvalue));
            Int = floor(Ni);
            [introw, ~, Nzero] = find(Int); % 找到非 0 个体的位置及值
            Newindex = cumsum([0 ;Nzero]);
            % 整数选取
            for i = 1:length(introw)
                for j = Newindex(i)+1:Newindex(i+1)
                    dad(j,:) = pop(introw(i),:);
                end
            end
            
            % 小数选取
            Float = mod(Ni, 1);
            [number, index] = sort(Float, 'descend');
            Left = row - sum(Nzero);
            if Left > 0
                dad(row:-1:row-Left+1, :) = pop(index(1:Left), :);
            end
            
            mom(1:row, :) = pop(randi([1 row], row, 1), :);
    end
    

end

function newpop = eselection(pop, bestfitvalue, bestx)
    global n varnum lb ub L
    spoint = cumsum([0 L]);
    
    for i = 1:n
        for j = 1:varnum
            startpoint = spoint(j) + 1;
            endpoint = spoint(j + 1);
            real(i, j) = decode(pop(i, startpoint:endpoint), lb(j), ub(j));
        end
    end
    
    fitvalue = fitnessfun(real);
    [Gbestfitvalue, Gbestindex] = max(fitvalue);
    [Gbadfitvalue, Gbadindex] = min(fitvalue);

    if Gbestfitvalue < bestfitvalue
        pop(Gbadindex(1), :) = bestx;
    end

    newpop = pop;
end
```

### 交叉

交叉：

- 二进制编码

对于二进制编码来说，存在单点、两点、多点和均匀交叉。

单点交叉，对于二进制编码一个交叉点，父代和母代相互交换该交叉点之后的编码。

两点交叉，对于二进制编码两个交叉点，父代和母代相互交换这两个交叉点之间的编码。

- 实值编码

离散交叉：父代、母代互换基因值。

算数交叉：$X' = rX + (1 - r)Y$，$Y' = (1-r)X+rY$ ，$r$ 为随机数。

平均交叉：算数交叉的特例，$r$ 为 0.5。

启发式交叉：往适应度高的父代交叉。

```matlab
function newpop = crossover(dad, mom, pc)
    [row, col] = size(dad);
    for i = 1:row
        if rand < pc
            cpoint = randi([1 col - 1]);
            newpop(i, :) = [dad(i, 1:cpoint) mom(i, cpoint+1:end)];
        else
            newpop(i, :) = dad(i, :);
        end
    end
end

function newpop = rcrossover(dad, pc)
    [row, col] = size(dad);
    % 实值交叉
    global ctype
    switch ctype
        case 1 % 离散交叉
            for i = 1:2:row-1
                if rand < pc
                    for j = 1:col
                        if randi([0 1]) == 1
                            newpop(i, j) = dad(i, j);
                            newpop(i+1, j) = dad(i+1, j);
                        else
                            newpop(i, j) = dad(i+1, j);
                            newpop(i+1, j) = dad(i, j);
                        end
                    end
                else
                    newpop(i, :) = dad(i, :);
                    newpop(i+1, :) = dad(i+1, :);
                end
            end
        case 2 % 算数交叉
            for i = 1:2:row-1
                if rand < pc
                    cpoint = randi([1 col]);
                    r = rand;
                    newpop(i, :) = r * dad(i, cpoint) * (1 - r) * dad(i + 1, cpoint);
                    newpop(i+1, :) = r * dad(i + 1, cpoint) * (1 - r) * dad(i, cpoint);
                else
                    newpop(i, :) = dad(i, :);
                    newpop(i+1, :) = dad(i+1, :);
                end
            end
        case 3
            for i = 1:2:row-1
                if rand < pc
                    cpoint = randi([1 col]);
                    r = 0.5;
                    newpop(i, :) = r * dad(i, cpoint) * (1 - r) * dad(i + 1, cpoint);
                    newpop(i+1, :) = r * dad(i + 1, cpoint) * (1 - r) * dad(i, cpoint);
                else
                    newpop(i, :) = dad(i, :);
                    newpop(i+1, :) = dad(i+1, :);
                end
            end
        case 4
            for i = 1:2:row-1
                if rand < pc
                    f1 = fitnessfun(dad(i, :));
                    f2 = fitnessfun(dad(i+1, :));
                    if f1 > f2
                        newpop(i, :) = dad(i, :);
                        newpop(i+1, :) = dad(i+1,:) + 1.2 * (dad(i,:) - dad(i+1,:));
                    else
                        newpop(i, :) = dad(i, :) + 1.2 * (dad(i+1,:) - dad(i,:));
                        newpop(i+1, :) = dad(i+1, :);
                    end
                else
                    newpop(i, :) = dad(i, :);
                    newpop(i+1, :) = dad(i+1, :);
                end
            end
    end
end


```

### 变异

二进制编码：

- 简单变异

  对于二进制编码，先选取一个从 [1 L] 上的随机点位，生成随机数小于规定变异概率，就发生变异，0 1 互变。

- 大变异

  简单变异，会使得算法过早收敛于一个非全局最优解。当某代所有个体集中到一起时，我们以一个远大于通常变异概率的概率执行一次变异操作，具体操作过程为：

  当某一代的最大适应度和平均适应度满足 $\alpha F_{max} < F_{avg}$ 关系时，执行大变异操作。$0.5 \lt \alpha \lt 1$， 称为密集因子。

  为了避免最优个体被大变异破坏，最优个体不参与大变异操作。

实值编码：

- 边界变异
  $$
  x'=\left\{
  \begin{array}{rcl}
  x_{max}, & {rand==1}\\
  x_{min}, & {rand==0}\\
  \end{array} \right.
  $$
  

- 非均匀变异，$t$ 代表当前当前迭代次数，$T$ 为总迭代次数，$b$ 为 2-5 的一个常量
  $$
  x'=\left\{
  \begin{array}{rcl}
  x+(x_{max}-x)(1-r^{b(1-t/T)}), & {rand==1}\\
  x-(x-x_{min})(1-r^{b(1-t/T)}), & {rand==0}\\
  \end{array} \right.
  $$
  

- 均匀变异，在基因值范围内生成随机数
- 高斯变异，由符合正态分布的随机数代替基因值，均匀分布可用中心极限定理、Box-Muller 方法生成标准正态分布。

```matlab
function newpop = mutation(pop, pm)
    [row, col] = size(pop);
    newpop = pop;
    for i = 1:row
        r = rand
        % 单个变异点位
        if rand < pm
            mpoint = randi([1 col]);
            newpop(i, mpoint) = ~pop(i, mpoint);
        end
    end
end

function newpop = Lmutation(pop, Lpm)
    global alpha T n varnum lb ub pm
    
    for i = 1:n
        for j = 1:varnum
            startpoint = spoint(j) + 1;
            endpoint = spoint(j + 1);
            real(i, j) = decode(pop(i, startpoint:endpoint), lb(j), ub(j));
        end
    end
    fitvalue = fitnessfun(real);
    [Fmax, Bestindex] = max(fitvalue);
    Favg = sum(fitvalue) / n;
    
    if alpha * Fmax < Fmax && iter < T
        [row, col] = size(pop);
        newpop = pop;
        for i = 1:row
            r = rand
            if rand < Lpm && i ~= Bestindex
                mpoint = randi([1 col]);
                newpop(i, mpoint) = ~pop(i, mpoint);
            end
        end
    else
        newpop = mutation(newpop, pm);
    end
end

function newpop = rmutation(pop, pm)
    global rmtype lb ub t T
    newpop = pop;
    switch rmtype
        case 1 % 均匀变异
            for i = 1:row
                mpoint = randi([1 col])
                if rand < pm
                    pop(i, mpoint) = lb(mpoint) + (ub(mpoint) - lb(mpoint)) * rand;
                    newpop(i, :) = pop(i, :);
                else
                    newpop(i, :) = pop(i, :);
                end
            end
        case 2 % 边界变异
            for i = 1:row
                mpoint = randi([1 col]);
                if rand < pm
                    if randi([0 1]) == 0
                        pop(i, mpoint) = lb(mpoint);
                    end
                    if randi([0 1]) == 1
                        pop(i, mpoint) = ub(mpoint);
                    end
                    newpop(i, :) = pop(i, :);
                else
                    newpop(i, :) = pop(i, :);
                end
            end
        case 3 % 非均匀变异
            for i = 1:row
                mpoint = randi([1 col]);
                r = rand;
                a = (1 - t/T);
                b = 5; % 2 - 5
                if rand < pm
                    if randi([0 1]) == 0
                        pop(i, mpoint) = pop(i, mpoint) + (ub(mpoint) - pop(i, mpoint)) * (1 - r^(a * b));
                    end
                    if randi([0 1]) == 1
                        pop(i, mpoint) = pop(i, mpoint) + (pop(i, mpoint) - lb(mpoint)) * (1 - r^(a * b));
                    end
                    newpop(i, :) = pop(i, :);
                else
                    newpop(i, :) = pop(i, :);
                end
            end
        case 4 % 高斯变异
            for i = 1:row
                mpoint = randi([1 col]);
                if rand < pm
                    mvalue = inf;
                    while mvalue < lb(mpoint) || mvalue > ub(mpoint)
                        mvalue = (lb(mpoint) + ub(mpoint)) / 2 + (ub(mpoint) - lb(mpoint)) / 6 * randn;
                    end
                    pop(i, mpoint) = mvalue;
                    newpop(i, :) = pop(i, :);
                else
                    newpop(i, :) = pop(i, :);
                end
            end
    end
end
```

### 自适应

引入自适应调整函数，使交叉概率和变异概率随个体适应度大小和群体的分散程度自动调整。

当群体有陷入局部最优解的趋势的时候，就相应地提高 $P_c$ $P_m$ 交叉概率和变异概率，当群体发散时就降低。

当个体的适应度接近当前种群的最大适应度时，就用较低的 $P_c$ $P_m$ ；当个体的适应度低于当前种群的平均适应度时，就用较大的 $P_c$ $P_m$。$f'$ 是两个待交叉个体中适应度较大的一个，$f$ 是待变异个体的适应度值。
$$
P_c=\left\{
\begin{array}{rcl}
k_1\frac{f_{max}-f'}{f_{max}-f_{avg}}, & { f' \ge f_{avg}}\\
k_2,  & {f' \lt f_{avg}}\\
\end{array} \right.
$$

$$
P_m=\left\{
\begin{array}{rcl}
k_1\frac{f_{max}-f}{f_{max}-f_{avg}}, & { f \ge f_{avg}}\\
k_2,  & {f \lt f_{avg}}\\
\end{array} \right.
$$



```matlab
function newpop = acrossover(dad, mom, pc1, pc2)
    global varnum L lb ub n
    [row, col] = size(dad);
    spoint = cumsum([0 L]);
    for i = 1:n
        for j = 1:varnum
            startpoint = spoint(j) + 1;
            endpoint = spoint(j + 1);
            real(i, j) = decode(dad(i, startpoint:endpoint), lb(j), ub(j));
        end
    end
    
    fitvalue = fitnessfun(real);
    Maxfitvalue = max(fitvalue);
    Meanfitvalue = sum(fitvalue) / n;
    
    for i = 1:n
        for j = 1:varnum
            startpoint = spoint(j) + 1;
            endpoint = spoint(j + 1);
            Mreal = decode(mom(i, startpoint:endpoint), lb(j), ub(j));
        end
        
        Mfit = fitnessfun(Mreal);
        if max(Mfit, fitvalue(i)) >= Meanfitvalue
            pc = pc1 * (Maxfitvalue - max(Mfit, fitvalue(i))) / (Maxfitvalue - Meanfitvalue);
        else
            pc = pc2;
        end
    end
    
    newpop = crossover(dad, mom, pc);
end

function newpop = amutation(pop, pm1, pm2)
    global varnum L lb ub n
    [row, col] = size(pop);
    spoint = cumsum([0 L]);
    for i = 1:n
        for j = 1:varnum
            startpoint = spoint(j) + 1;
            endpoint = spoint(j + 1);
            real(i, j) = decode(pop(i, startpoint:endpoint), lb(j), ub(j));
        end
    end
    
    fitvalue = fitnessfun(real);
    Maxfitvalue = max(fitvalue);
    Meanfitvalue = sum(fitvalue) / n;
    
    for i = 1:n
        f = fitvalue(i);
        if f >= Meanfitvalue
            pm = pm1 * (Maxfitvalue - f) / (Maxfitvalue - Meanfitvalue);
        else
            pm = pm2;
        end
    end
    
    newpop = mutation(pop, pm);
end
```

### 运行

![](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210511185624354.png)

遗传算法的运行具有随机性，有时需要多运行几次。

```matlab
f = @(x) 11 * sin(6 * x) + 7 * cos(5 * x);
fplot(f, [-pi pi])
hold on
h = plot(0, 0, '*');

global M varnum n lb ub L q sn alpha T pm ftype
ftype = 5;
M = 2;
varnum = 1;
n = 200;
lb = -pi;
ub = pi;
sn = 2;
eps = 1e-2;
pc = 0.7; % 交叉概率
pc1 = 0.5;
pc2 = 0.9;
pm1 = 0.01;
pm2 = 0.05;
alpha = 0.5;
T = 500; % 大变异运行阈值
pm = 0.005; % 变异概率
Lpm = 0.05; % 大变异概率
maxgen = 200; % 迭代次数
q = 0.5; % 排序选择参数

for i = 1:varnum
    L(i) = ceil(log2((ub(i) - lb(i)) / eps + 1)); 
end

LS = sum(L); % 总编码长度
spoint = cumsum([0 L]); % 对于总编码区间长度分割
pop = randi([0 1], n, LS); % 生成随机种群

for iter = 1:maxgen
    
    for i = 1:n
        for j = 1:varnum
            startpoint = spoint(j) + 1;
            endpoint = spoint(j + 1);
            real(i, j) = decode(pop(i, startpoint:endpoint), lb(j), ub(j));
        end
    end
    
    fitvalue = fitnessfun(real);
    [bestfitvalue, bestindex] = max(fitvalue);
    bestx = pop(bestindex, :);
    
    fval = objfun(real);
    h.XData = real;
    h.YData = fval;
    pause(0.01);
    
    %% 选择
    [dad, mom] = selection(pop, fitvalue, 3);
    
    %% 交叉
    % newpop = crossover(dad, mom, pc); 
    newpop = acrossover(dad, mom, pc1, pc2); % 自适应交叉
    
    %% 变异
    % newpop = Lmutation(newpop, Lpm); 大变异
    newpop = amutation(newpop, pm1, pm2); % 自适应变异
    
    %% 精英保存
    newpop = eselection(newpop, bestfitvalue, bestx);
    
    pop = newpop;
end

for i = 1:n
    for j = 1:varnum
        startpoint = spoint(j) + 1;
        endpoint = spoint(j + 1);
        real(i, j) = decode(pop(i, startpoint:endpoint), lb(j), ub(j));
    end
end

fitvalue = fitnessfun(real);
[bestfitness, bestindex] = max(fitvalue);
bestindividual = real(bestindex, :)
fval = objfun(bestindividual)

plot(bestindividual, fval, '*')
```

## Matlab 工具箱

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blog1076860-20190426210952593-927305408.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blog1076860-20190426211028991-1719003432.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blog1076860-20190426211101818-1132986484.png)

```matlab
function [sol, fitnessVal] = fitness(sol, options)
	x = sol(1);
	fitnessVal = x + 10*sin(5*x)+7*cos(4*x);
end
f = @(x) x + 10*sin(5*x)+7*cos(4*x);

fplot(f, [0 9])
title('y = x + 10*sin(5*x) + 7*cos(4*x)')


initPop = initializega(50, [0 9], 'fitness');

[x endPop bpop trace] = ga([0 9],'fitness',[],initPop,[1e-6 1 1],'maxGenTerm',25,...
                           'normGeomSelect',0.08,'arithXover',2,'nonUnifMutation',[2 25 3]);
x
hold on
plot (endPop(:,1),endPop(:,2),'ro')

%% 绘制迭代进化曲线
figure(2)
plot(trace(:,1),trace(:,3),'b:')
hold on
plot(trace(:,1),trace(:,2),'r-')
xlabel('Generation'); ylabel('Fittness');
legend('Mean Fitness', 'Best Fitness')
```

