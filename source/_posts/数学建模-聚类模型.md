---
title: 数学建模-聚类模型
date: 2021-05-14 20:01:22
mathjax: true
tag: [数学建模]
---



# 聚类模型

聚类，就是将样本划分为由类似的对象组成的多个类的过程。聚类后，我们可以更加准确的在每个类中单独使用统计模型进行估计、分析或预测；也可以探究不同类之间的相关性和主要差异。

分类是已知类别的，聚类未知。

样本与样本之间的常用距离有欧式距离、或者曼哈顿距离等。

也可以将指标和样本矩阵倒转，指标进行聚类，以相关系数衡量夹角距离。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426195316752.png)

# K-means 算法

1. 指定需要划分的簇的个数K值（类的个数）
2. 随机地选择K个数据对象作为初始的聚类中心
3. 计算其余的各个数据对象到这K个初始聚类中心的距离，把数据对象划归到距离它最近的那个中心所处在的簇类中
4. 调整新类并且重新计算出新类的中心
5. 循环步骤 3 和 4，看中心是否收敛（不变），如果收敛或达到迭代次数则停止循环
6. 结束

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426193957697.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426194018560.png)

优点：

1. 算法简单、快速
2. 对处理大数据集，该算法是相对高效率的

缺点：

1. 用户必须事先给出要生成的簇的数目K
2. **对初值敏感** （不同初值会分类结果不同）
3. **对于孤立点数据敏感** （孤立点不能单独形成类）

# K-means++ 算法

选择初始聚类中心的基本原则是：初始的聚类中心之间的相互距离要尽可能的远。

对 **初始化K个聚类中心** 进行了优化

1. 随机选取一个样本作为第一个聚类中心
2. 计算每个样本与当前已有聚类中心的最短距离（即与最近一个聚类中心的距离），这个值越大，表示被选取作为聚类中心的概率较大；最后，用轮盘法（依据概率大小来进行抽选）选出下一个聚类中心。
3. 重复步骤 2，直到选出K个聚类中心。

分几类主要取决于个人的经验与感觉，通常的做法是多尝试几个 K 值，看分成几类的结果更好 **解释**，更符合分析 **目的 **等。

数据的量纲不一致时，需要标准化。

## SPSS 操作

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426194949309.png)

# 系统（层次）聚类

系统聚类的合并算法通过计算两类数据点间的距离，对最为接近的两类数据点进行组合，并反复迭代这一过程，直到将所有数据点合成一类，并生成聚类谱系图。

类与类之间的常用距离：最短距离法、最长距离法、组间平均连接法、组内平均连接法、重心法等。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426195100447.png)



1. 将每个对象看作一类，计算两两之间的最小距离
2. 将距离最小的两个类合并成一个新类
3. 重新计算新类与所有类之间的距离
4. 重复 2、3 两步，直到所有类最后合并成一类
5. 结束

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426195951206.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426200151578.png)

## SPSS 操作

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426200251752.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426200357762.png)

## 估计聚类数量

**肘部法则**：通过图形大致的估计出最优的聚类数量。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426200530564.png)

把数据粘贴到Excel表格中，并按照降序排好。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426200744139.png)

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426200859594.png)

当指标个数为 2 或者 3 的时候可以再做散点图画图。

# DBSCAN 算法

一种基于密度的聚类方法，聚类前不需要预先指定聚类的个数，生成的簇的个数不定（和数据有关）。要求聚类空间中的一定区域内所包含对象（点或其他空间对象）的数目不小于某一给定阈值。能在具有 **噪声 ** 的空间数据库中发现任意形状的簇，可将密度足够大的相邻区域连接，能有效处理异常数据。

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426201112210.png)

- 核心点及边界点：在半径 Eps 内含有不少于 MinPts 数目的点；在半径 Eps 内点的数量小于 MinPts，落在核心点的邻域内。
- 噪音点：既不是核心点也不是边界点的点，单独成点

![](https://hauk-blog.oss-cn-hangzhou.aliyuncs.com/blogimage-20210426201348799.png)

优点：

1. 基于密度定义，能处理任意形状和大小的簇
2. 可在聚类的同时发现异常点
3. 与K-means比较起来，不需要输入要划分的聚类个数

缺点：

1. 输入参数 ε 和 Minpts 敏感，确定参数困难
2. 由于DBSCAN算法中，变量 ε 和 Minpts 是全局唯一的，当聚类的密度不 **均匀** 时，聚类距离相差很大时，聚类质量差
3. 当数据量大时，计算密度单元的计算复杂度大

做出散点图后发现数据表现得很 "DBSCAN"，这时候再用 DBSCAN 进行聚类。

```matlab
function [IDX, isnoise]=DBSCAN(X,epsilon,MinPts)
	C=0;
	n=size(X,1);
	IDX=zeros(n,1);
	D=pdist2(X,X); % 生成距离矩阵
	visited=zeros(n,1);
	isnoise=zeros(n,1);
	for i=1:n
		if visited(i)==0
			visited(i)=1;
			Neighbors=RegionQuery(i);
			if numel(Neighbors)<MinPts
				isnoise(i)=1;
			else
				C=C+1;
				ExpandCluster(i,Neighbors,C);
			end
		end
	end
	
	function ExpandCluster(i,Neighbors,C)
		IDX(i)=C;
		k = 1;
		while true
			j = Neighbors(k);
			if visited(j)==0
				visited(j)=1
				Neighbors2=RegionQuery(j);
				if numel(Neighbors2)>=MinPts
					Neighbors=[Neighbors Neighbors2];
				end
			end
			if IDX(j)==0
				IDX(j)=C;
			end
			k = k + 1;
			if k > numel(Neighbors)
                break;
            end
		end
	end
	
	function Neighbors=RegionQuery(i)
        Neighbors=find(D(i,:)<=epsilon);
    end
end

function PlotClusterinResult(X, IDX)
	k=max(IDX);
	Colors=hsv(k);
	Legends = {};
	for i=0:k
		Xi=X(IDX==i,:);
		if i~=0
			Style = 'x';
			MarkerSize = 8;
			Color = Colors(i,:);
			Legends{end+1} = ['Cluster #' num2str(i)];
		else
			Style = 'o';
			MarkerSize = 6;
			Color = [0 0 0];
			if ~isempty(Xi)
                Legends{end+1} = 'Noise';
            end
		end
		
		if ~isempty(Xi)
            plot(Xi(:,1),Xi(:,2),Style,'MarkerSize',MarkerSize,'Color',Color);
        end
        hold on
	end
	hold off
    axis equal
    grid on
    legend(Legends)
    legend('Location', 'NorthEastOutside')
end

epsilon=0.5;
MinPts=10;
IDX=DBSCAN(X,epsilon,MinPts);
PlotClusterinResult(X, IDX);
```



